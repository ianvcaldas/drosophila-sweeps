
Archived entries from file /Users/ian/ciencia/projects_202109_drosophila-sweeps/todo.org

* 2021

** 2021-09 September

*** 2021-09-30 Thursday
**** DONE [#B] Simulate with log-scale normalized statistics. [100%]
CLOSED: [2021-09-30 Thu 18:39] SCHEDULED: <2021-09-30 Thu>
:PROPERTIES:
:ARCHIVE_TIME: 2021-10-04 Mon 11:31
:ARCHIVE_FILE: ~/ciencia/projects_202109_drosophila-sweeps/todo.org
:ARCHIVE_OLPATH: Sweeps
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:END:

- State "DONE"       from "DOING"      [2021-09-30 Thu 18:39]
- State "DOING"      from "TODO"       [2021-09-30 Thu 13:03]
- [X] Check if simulations are saving a log-transformed .tar of data.
- [X] If not, implement that in simulations: make a folder of unique npys with the log data, then tar that.
- [X] Test the new stuff locally.
- [X] Check if cluster scripts are saving the .tar of log-transformed data.
- [X] If not, make them save that as well.
- [X] Git update everything.
- [X] Move existing cluster simulations to their own folder, create a new one for raw simulations.
- [X] Now we just need to re-run cluster simulations, yet again. Do this *after* debugging the new simulation results.

**** DONE [#A] Debug feature calculation failure with zero segregating sites. [100%]
CLOSED: [2021-09-30 Thu 16:56] SCHEDULED: <2021-09-30 Thu>
:PROPERTIES:
:ARCHIVE_TIME: 2021-10-04 Mon 11:31
:ARCHIVE_FILE: ~/ciencia/projects_202109_drosophila-sweeps/todo.org
:ARCHIVE_OLPATH: Sweeps
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:END:

- State "DONE"       from "TODO"       [2021-09-30 Thu 16:56]
- [X] Add a config with mutation rate of zero to produce zero segregating sites all the time.
- [X] Change =02_run= to use that config for now.
- [X] Check that we get the same =genfromtxt= error using that config.
- [X] Reproduce =genfromtxt= error in an interactive session.
- [X] What is the error caused by?
- [X] Fix it in an interactive session.
- [X] Confirm that we read in 0 segregating sites properly.
- [X] Confirm that we read in 1 segregating site properly.
- [X] Confirm that we read in >1 segregating sites properly.
- [X] Check timing of new function vs. old function for >1 segregating sites.
- [X] Put new function in the script.
- [X] Make feature calculation work with 0 segregating sites.
- [X] Run simulations and check that everything runs, and features are calculated properly.
- [X] Clean output folder of simulations.
- [X] Change =02_run= back to its normal state.
- [X] Put zero-mutations simulation in as a simtest folder.
- [X] Git update everything.


** 2021-10 October

*** 2021-10-01 Friday
**** DONE [#A] Debug new simulation results. [100%]
CLOSED: [2021-10-01 Fri 11:16] SCHEDULED: <2021-09-30 Thu>
:PROPERTIES:
:ARCHIVE_TIME: 2021-10-04 Mon 11:31
:ARCHIVE_FILE: ~/ciencia/projects_202109_drosophila-sweeps/todo.org
:ARCHIVE_OLPATH: Sweeps
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:END:

- State "DONE"       from "DOING"      [2021-10-01 Fri 11:16]
- State "DOING"      from "TODO"       [2021-09-30 Thu 13:03]
- My hypothesis was that all SLURM tasks from a single array job are happening in the same workdir, and thus the snakemake input/output calculations are going haywire.
- It turns out that the =/workdir= scratch space on =cbsubscb10= was 100% full, so you couldn't =mkdir= a folder there; I was getting this mysterious "Input/output error". So instead of creating a directory in scratch and switching to it, we were running simulations from inside home in multiple jobs and tasks, causing a huge amount of race conditions. The temporary solution is to avoid =cbsubscb10= for now and hope no other compute nodes have the same problem.
- [X] Wait for everything to run in the cluster.
- [X] Download the tars.
- [X] Check the SLURM output for the logs.
- [X] Does every data tar contain the same NPY files? No...
- [X] Change name of output file to include slurm job array ID. Locally.
- [X] Change workdir to include slurm job array ID. Locally.
- [X] slurm array task id vs. slurm array job id.
- [X] Git update just the slurm script.
- [X] Clean cluster folder of slurm outputs.
- [X] Check workdirs.
- [X] Confirm cluster slurm output are alright.
- [X] Re-run with very few simulations jobs; comment original amounts out.
- [X] Confirm it runs properly.
- [X] Confirm there are not extra files in =~/drosophila-sweeps=.
- [X] Git checkout of the slurm sbatch script so simulation amounts are back to normal.
- [X] Update git from the cluster: fetch, merge, then commit and push.
- [X] Delete local simulations.
- [X] Read SLURM outputs to see what failed.
- [X] Make testing SLURM scripts.
- [X] See if I run into the same mistake as before.
- [X] Re-run simulations with only a couple of runs.
- [X] Clean up =benchmark=, =output= and =bin= from the main folder.
- [X] Do not use cbsubscb10.
- [X] Try re-running the big ones now.

*** 2021-10-05 Tuesday
**** DONE Combine simulations, including log-transformed data. [100%]
CLOSED: [2021-10-05 Tue 15:34] SCHEDULED: <2021-10-04 Mon>
:PROPERTIES:
:ARCHIVE_TIME: 2021-10-27 Wed 11:29
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:END:
  
- State "DONE"       from "DOING"      [2021-10-05 Tue 15:34]
- State "DOING"      from "TODO"       [2021-10-04 Mon 18:40]
- [X] Grep the slurm outputs for "Input/output" errors.
- [X] Check if the main folder does not have an =output=, etc.
- [X] Wait for everything to run.
- [X] Check that the log-transformed =tar= of data are there.
- [X] Remove old simulations.
- [X] Rename folder of new simulations to =raw-simulations=.
- [X] Download new data.
- [X] Replace current data with new data that includes log-transformed data.
- [X] Additional rule for combining simulation results, but using the log-transformed data this time. This can be a simple parameter passed to the simulation combination notebook.
- [X] Make features and logdata outputs of the simulation combination rule.
- [X] Modify =03_config.yaml= back to using real data.
- [X] Run everything to combine data.
- [X] Confirm that things ran as planned.

*** 2021-10-18 Monday
**** DONE Snakemake rules for model training. [100%]
CLOSED: [2021-10-18 Mon 12:35]
:PROPERTIES:
:ARCHIVE_TIME: 2021-10-27 Wed 11:29
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:END:

- State "DONE"       from "DOING"      [2021-10-18 Mon 12:35] \\
  Brainstormed what the Snakemake pipeline for training models would look like. Still missing: the pipeline for converting inferences on training, validation, and testing datasets into performance metrics.
- State "DOING"      from "TODO"       [2021-10-18 Mon 12:00]
- [X] Use the fastai conda environment.
- [X] Read the code for building a model. What steps happen in it?
- [X] Read the code for training a model. What steps happen in it?
- [X] How would we turn these steps into rules with inputs and outputs?
- [X] List in config for datasets to train models with.
- [X] A general rule for training a model and outputting trained model, reports of fitting, and validation results.
- [X] One rule per target of inference. 
- [X] Use multiple cores when training, add number of cores to the snakemake rule as well.
- [X] Use a smaller dataset for training.

*** 2021-10-20 Wednesday
**** DONE Toy model training implementation. [100%]
CLOSED: [2021-10-20 Wed 19:00]
:PROPERTIES:
:ARCHIVE_TIME: 2021-10-27 Wed 11:29
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:END:

- State "DONE"       from "DOING"      [2021-10-20 Wed 19:00]
- State "DOING"      from "TODO"       [2021-10-20 Wed 16:01]
- [X] Add lists of training and testing datasets to config; add list of inference targets to config.
- [X] Expand those lists into the final outputs of the process, the testing inferences. Add that into the top rule.
- [X] Write toy Test rule with =touch=.
- [X] Write toy Fit rule with =touch=.
- [X] Write toy Split rule with =touch=.
- [X] Write toy Balance rule with =touch=.
- [X] Add outcomes of overfitting analysis to top rule. Try and keep that in as few files as possible.
- [X] Add toy rule to combine SimpleFit outcomes with =touch=.
- [X] Add toy SimpleFit rule with =touch=.

*** 2021-10-27 Wednesday
**** DONE Skeleton training implementations. [100%]
CLOSED: [2021-10-27 Wed 13:18]
:PROPERTIES:
:ARCHIVE_TIME: 2021-11-01 Mon 15:01
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:

- State "DONE"       from "DOING"      [2021-10-27 Wed 13:18]
- State "DOING"      from "TODO"       [2021-10-27 Wed 12:27]
Convert rules into notebooks or scripts that load the right packages, produce out the right files, and use the right number of cores, instead of simply using =touch=.

- [X] Balance rule. [7/7]
  - [X] Import pandas.
  - [X] Dictionary of balancing function per target.
  - [X] Current target is a wildcard.
  - [X] Produce one output only, the one for the target.
  - [X] Skeleton functions in =prepare_data.py=.
  - [X] Delete outputs and run test.
  - [X] Columns have mixed types?
- [X] Split rule. [10/10]
  - [X] Close notebook, re-run with new conda env.
  - [X] Check sklearn version; add that to the env.
  - [X] Close notebook again, re-run again with new env.
  - [X] Now complete the notebook: stratify, use random seed, shuffle.
  - [X] Turn validation % into a snakemake parameter.
  - [X] Put stratifying column in =prepare_data= and import that into notebook.
  - [X] Run notebook to see the files appear.
  - [X] Check label proportions and sizes of outputs.
  - [X] Convert notebook back to using the proper validation % before closing it.
  - [X] Re-run, forcing the rule but not editing the notebook.
- [X] Fit rule. [2/2]
  - [X] Import fastai.
  - [X] Produce every output in the most basic way possible.
- [X] SimpleFit rule. [3/3]
  - [X] Variation of Fit notebook, but with a different parameter.
  - [X] Run snakemake with the target being a fit replicate.
  - [X] Make a toy 1-line DF for the fit report instead of a touch.
- [X] Aggregating overfitting replicates rule. [2/2]
  - [X] Script, not notebook.
  - [X] Use simple pandas concat.
- [X] Update git and github.

*** 2021-10-28 Thursday
**** DONE Split training and validation at the start. [100%]
CLOSED: [2021-10-28 Thu 16:00]
:PROPERTIES:
:ARCHIVE_TIME: 2021-11-01 Mon 15:01
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:
- State "DONE"       from "DOING"      [2021-10-28 Thu 16:00]
- State "DOING"      from              [2021-10-27 Wed 15:56]
- [X] Write question down to understand the issue yourself.
- [X] Ask about differences.
- [X] Is it interesting to do?
- [X] Plan reworking of rules.
- [X] Implement reworking in terms of Snakefile wildcards and rules.
  - [X] Train/valid split is done once per training data, as the first thing. Output folder.
  - [X] Balancing rule takes the train/valid splits as input, happens once per training data and once per target. Output folder.
  - [X] Fitting rules (both) take in the balanced datasets as input.
- [X] Confirm with =-n= that all necessary files are there.
- [X] Produce a DAG in PDF format with dot. (Check bash history to see how.)
- [X] Implement reworking in terms of skeleton notebooks.
  - [X] Train/valid split.
  - [X] Balancing.
  - [X] Fitting.
- [X] Delete current outputs, test one output file to see if it works.
- [X] Git update.
  
I have a main dataset with labels A, B, C in equal proportions. I want to train two models: model 1 is a 3-way classification A vs. B vs. C, and model 2 is a binary classification A vs. (B + C). For that second one labels B and C are downsampled so (num A) = (num B + C). I can do training/testing split in two ways:

1) Do it once, at the start, so I've got a fixed A+B+C training dataset and a fixed A+B+C testing set. For the binary model, downsample those training and testing sets. This way, any example x_i is always going to be in the training set for both models or the testing set for both models.

2) Do it one time per model. Do a training/testing split for model 1. Then, downsample the data and do a separate training/testing split for model 2. This way, an example x_i that's training for model 1 may be testing for model 2.

I don't have a great intuition for what's "best" among these. Intuition tells me option (1) might propagate any weird bias you might end up having by chance in your original train/test split to every model. While option (2) makes it harder to compare the models. Any thoughts?

** 2021-11 November

*** 2021-11-10 Wednesday
**** DONE [#3] New plot of selection strength performance. [100%]
CLOSED: [2021-11-10 Wed 12:00]
:PROPERTIES:
:ARCHIVE_TIME: 2021-11-23 Tue 17:48
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:

- State "DONE"       from "TODO"       [2021-11-10 Wed 12:00]
- State "DONE"       from "TODO"       [2021-11-09 Tue 12:19]
- [X] Find notebook with the right plotting code.
- [X] Reconstruct plot with both sel. strength and sweep mode performance.
- [X] Load dataframe with all s predictions for the validation set.
- [X] Calculate (predicted s/true s), not in log scale, for every data point.
- [X] Get a list of all selection splits, with separate values for min and max.
- [X] For each selection split, calculate the mean of that value.
- [X] Create a DF with split and mean relative error.
- [X] Join that DF with the original one from the notebook.
- [X] Plot the mean relative error by selection bracket.
- [X] Plot mean(abs((predicted - true)/true)) instead.
- [X] What are the conclusions?
- [X] Send that to Philipp.

Sel. strength performance vs. sel. strength bracket: Instead of showing 1-RMSE, show mean(predicted s/true s). (Not in log scale!) There is a thing called "root mean squared relative error". Philipp would call it "mean relative error". Philipp thinks this would turn results around and say that we do better at strong sweeps than weak ones.


**** DONE [#3] Finalize skeleton model fitting implementations. [100%]
CLOSED: [2021-11-10 Wed 21:13]
:PROPERTIES:
:ARCHIVE_TIME: 2021-11-23 Tue 17:48
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:

- State "DONE"       from "DOING"      [2021-11-10 Wed 21:13]
- State "DOING"      from "TODO"       [2021-11-10 Wed 16:30]
- [X] First workflow modifications. [10/10]
  - [X] Modify existing rule or add rule?
  - [X] Tar empirical windows.
  - [X] Test that entire workflow works with tar windows.
  - [X] Add log windows to empirical features rule.
  - [X] Implement log windows in notebook.
  - [X] Add a waiting rule for log-tar windows.
  - [X] Tar log empirical windows.
  - [X] Add log windows to the =all= rule.
  - [X] Test that the entire workflow still works.
  - [X] Git update.
- [X] Test application rules in workflow 3. [4/4]
  - [X] Same notebook of trained model application for both.
  - [X] For now, just touching outputs is fine.
  - [X] Test that everything works fine.
  - [X] Git update.
- [X] Delete outputs and run everything in workflow 3. [5/5]
  - [X] Training data, model fitting, trained models, all inferences.
  - [X] Add benchmarks and notebook logs for everything.
  - [X] Add wildcards to benchmarks and logs.
  - [X] Test that everything works fine.
  - [X] Git update.
- [X] Every benchmark for workflow 1 goes into a =prepare= folder.
- [X] Every benchmark for workflow 2 goes into a separate folder as well.

*** 2021-11-11 Thursday
**** DONE [#3] Re-draw training and validation datasets for overfitting replicates. [100%] 
CLOSED: [2021-11-11 Thu 14:34]
:PROPERTIES:
:ARCHIVE_TIME: 2021-11-23 Tue 17:48
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:
- State "DONE"       from "DOING"      [2021-11-11 Thu 14:34]
- State "DOING"      from "TODO"       [2021-11-11 Thu 14:32]
- [X] New required inputs.
- [X] Can we just use the existing rule?
- [X] Add rules if needed.
- [X] Adapt notebook if necessary. (=params.random_seed= is optional.)
- [X] Double-check benchmarks and logs of overfitting rules.
- [X] Run everything, test.

**** DONE [#3] Train-test splitting notebook. [100%]
CLOSED: [2021-11-11 Thu 15:28]
:PROPERTIES:
:ARCHIVE_TIME: 2021-11-23 Tue 17:48
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:

- State "DONE"       from "TODO"       [2021-11-11 Thu 15:28]
- [X] Remove lines corresponding to failed simulations.
- [X] Remove neutral simulations.
- [X] Downsample so all four regimes are equally represented. Possibly so that they all have exactly 4000 cases for training and 1000 for validation.

*** 2021-11-12 Friday
**** DONE [#3] Rule for cleaning parameters. [100%]
CLOSED: [2021-11-12 Fri 11:12]
:PROPERTIES:
:ARCHIVE_TIME: 2021-11-23 Tue 17:48
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:

- State "DONE"       from "TODO"       [2021-11-12 Fri 11:12]
Since the train-test split runs once for every overfitting replicate, if we downsample the data here, each replicate will get a different dataset of 5000 sweeps for each mode. We want each replicate to have the same dataset. Meaning we need to add a new rule between getting the parameters and splitting them into training and testing datasets.

- [X] Add a rule for cleaning parameters before the train-test split. Should run once per training dataset.
- [X] Update input of rule for checking the training distribution of cleaned simulations.
- [X] Rule removes failed simulations, neutral simulations, and downsamples to a fixed number of cases per selection regime (5000, make it a snakemake parameter).
- [X] Move that code over from the current notebook on train-test split to a script.
- [X] Change input of the train-valid split to accomodate the new rule.
- [X] Change input of the overfitting splitting rule to accomodate the new rule as well.
- [X] Confirm that train-test split is shuffling cases.
- [X] Test it, check that it works.
- [X] Updage git.

**** DONE [#3] Balancing functions. [100%]
CLOSED: [2021-11-12 Fri 15:42]
:PROPERTIES:
:ARCHIVE_TIME: 2021-11-23 Tue 17:48
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:

- State "DONE"       from "TODO"       [2021-11-12 Fri 15:42] \\
  Changed my mind, there's a lot of changes to make.
Should: Add necessary columns.
Should: Downsample to match.

- [X] Balance log selection strength.
- [X] Balance sweep mode.
- [X] Balance hard vs. soft.
- [X] Balance SGV vs. RNM.
- [X] Move code back to script.
- [X] Complete the "target columns".
- [X] Compare with previous data preparation functions.
- [X] Create column of "true softness" when balancing the data.
- [X] Redo target columns and balancing functions to account for true softness.

*** 2021-11-23 Tuesday
**** DONE [#3] Number of simulations. [100%]
CLOSED: [2021-11-23 Tue 12:56]
:PROPERTIES:
:ARCHIVE_TIME: 2021-11-23 Tue 17:48
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:

- State "DONE"       from "TODO"       [2021-11-23 Tue 12:56]
- State "DOING"      from "TODO"       [2021-11-16 Tue 15:30]
  
We start with a training that has:
- Failed simulations.
- Neutral simulations.
- Soft sweeps that aren't really soft, that only have 1 adaptive allele.
We need to get rid of all these things for training data.
We want to /add/:
- Sweep mode with true soft sweeps.
- Log of selection coefficient.
And after this, we want to make training data 4000+1000 samples.
For robustness datasets, you want to /add/ the columns but remove only the failed simulations, since neutrality and hard-like soft sweeps are all informative. We should have columns that indicate their existence, though.

So this is universal, for every single dataset:
1. Remove failed simulations.
2. Make a column for sweep mode: neutral, hard, true sgv, true rnm, fake sgv, fake rnm.
3. Make a column for log selection coefficient.
4. Report how many successful and failed simulations are there for each sweep mode.
5. Report distributions of successful and failed simulations per sweep mode.

For training and validation data:
1. Remove neutral, fake sgv, and fake rnm sweep modes.
2. Save those removed cases for a full validation dataset.
3. Subset to 5000 cases per mode.

My work so far is in =notebooks/inference/Untitled.ipynb=.

- [X] Plan data preparation for /training/ and /validation/ datasets, write it all down.
- [X] Plan data preparation for /robustness/ datasets, write it all down.
- Universal rules are applied in the =clean= rule:
  - [X] Adapt =make-data-report= for the case when there is only one simulation status.
  - [X] Fold all of =make-data-report= into a single function.
  - [X] Move that into the =clean= script.
  - [X] Invoke it separately for the successful and the failed simulations.
  - [X] Add all those reports to the =clean= rule outputs.
  - [X] Test it all.
- Train/validation rules are applied in the =split= rule:
  - [X] Remove neutral, fake sgv, and fake rnm sweep modes.
  - [X] Save those removed cases for a full validation dataset.
  - [X] Subset to 5000 cases per mode.
- [X] Make the useful functions easy to reuse by putting them in utils.
- [X] Transfer tain/valid split to a script.
- [X] What to do with the =balancing= rule?
- [X] Check workflow.
- [X] Check that balanced training datasets have equal number of target cases.
- [X] Clean unused notebooks.
- [X] How many simulations have we got left? 4000 + 1000?
- [X] Black every script.
- [X] Update git.

*** 2021-11-24 Wednesday
**** DONE [#1] Read about Python's tar package.
CLOSED: [2021-11-24 Wed 16:10]
:PROPERTIES:
:ARCHIVE_TIME: 2021-12-21 Tue 12:44
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:
- State "DONE"       from "DOING"      [2021-11-24 Wed 16:10]
- State "DOING"      from "TODO"       [2021-11-24 Wed 16:07]
- Module of the Week.
- Official documentation.

**** DONE [#3] Simulate more data. [5/5]
CLOSED: [2021-11-24 Wed 15:45]
:PROPERTIES:
:ARCHIVE_TIME: 2021-12-21 Tue 12:44
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:

- State "DONE"       from "DOING"      [2021-11-24 Wed 15:45]
- State "DOING"      from "TODO"       [2021-11-24 Wed 12:58]
Around 50% of RNM sweeps are hard-like.
Around 11% of SGV sweeps are hard-like.

To get 5000 true sweeps of each, I need more training simulations.

- [X] Update github repo, locally and on the cluster.
- [X] Change simulation amounts.
- [X] Double-check simulation destiation folders.
- [X] Run simulations.
- [X] Check that simulations are running okay.


** 2021-12 December

*** 2021-12-01 Wednesday
**** DONE [#3] Get new simulations. [2/2]
CLOSED: [2021-12-01 Wed 14:25]
:PROPERTIES:
:ARCHIVE_TIME: 2021-12-21 Tue 12:44
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:

- State "DONE"       from "TODO"       [2021-12-01 Wed 14:25]
- [X] Check if simulations ran okay in the cluster.
- [X] Download them.

*** 2021-12-21 Tuesday
**** DONE Prepare new simulation data. [7/7]
CLOSED: [2021-12-21 Tue 13:23]
:PROPERTIES:
:ARCHIVE_TIME: 2021-12-21 Tue 14:59
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:
- State "DONE"       from "DOING"      [2021-12-21 Tue 13:23]
- State "DOING"      from "TODO"       [2021-12-21 Tue 12:15]
- [X] Verify where the folders specifications are in the config.
- [X] What do the rules do? What's a placeholder and what isn't?
- [X] Just run all the rules.
- [X] How to combine different simulation runs together?
- [X] Run all the rules, again.
- [X] Check that simulation numbers add up.
- [X] Update git: cluster to repo. Repo to local. Local to repo.

* 2022

** 2022-01 January

*** 2022-01-04 Tuesday
**** DONE [#1] Model fitting notebook. [30/30]
CLOSED: [2022-01-04 Tue 15:50]
:PROPERTIES:
:ARCHIVE_TIME: 2022-01-12 Wed 12:31
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:

- State "DONE"       from "DOING"      [2022-01-04 Tue 15:50]
- State "DOING"      from "TODO"       [2022-01-03 Mon 16:38]
- [X] Untar the simulation data.
- [X] In =utils/prepare_data.py=, the target columns should be the right ones.
- [X] Put data in DataLoaders.
- [X] Create a Learner from the DataLoaders and the torch model.
- [X] Find the Loss functions from the previous project iteration and add them to the current training Dataset object.
- [X] Turn labels into number-encoded ones.
- [X] Debug the Learner until it Fits properly.
- [X] Do I need to add a softmax layer manually for classification?
- [X] Test everything with regression and classification both.
  - [X] Continous labels are returned for regression task.
  - [X] Integer labels with class ID are returned for classification task.
- [X] Clean previous snakemake conda temp notebooks.
- [X] Save the learned parameters from the model.
- [X] Need to make sure that using log data runs as smoothly as using the regular data.
- [X] Save the model fit history, if requested.
- [X] Save predictions, if requested.
  - [X] Classification predictions get uuid, probabilities for everything, predicted class, predicted class ID, true class, and true class ID.
  - [X] Regression predictions get uuid, predicted and true values.
  - [X] Don't have "(true)" in label names, might get confused with "predicted" and "true" values.
- [X] Number of epochs of training is in =project_parameters=, indexed by target.
  - [X] Implement in script.
  - [X] Implement in notebook.
- [X] Snakemake parameter to train for only 1 epoch, for debugging.
  - [X] Implement in snakefile.
  - [X] Implement in notebook.
- [X] Save functions to =utils=, keep them out of the notebook. Apply =Black= to them.
- [X] Delete existing intermediate files: we're starting from scratch this time.
- [X] Run everything together. Comment out overfitting runs to save on time.
- [X] Check outputs.
- [X] Update git.

*** 2022-01-12 Wednesday
**** Model training steps.
:PROPERTIES:
:ARCHIVE_TIME: 2022-01-12 Wed 12:31
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:

For one training dataset, one inference target, and one group of input features:
1. Read in data parameters.
2. Add new transformed parameters relevant for the inference target.
3. Subset it to relevant data points for the inference target.
4. Balance data so all labels have the same number of instances.
5. Do training/validation split.
6. Report distribution of parameters in training and validation data.
7. Convert training and validation data to format appropriate for framework.
8. Create model object according to inference target and number of features.
9. Get a model
   - Fit model, report fitting process, and save model parameters; or
   - Load pre-trained model.
10. Save inferences on training and validation datasets.
11. Load testing datasets, can be more than one.
12. Convert testing datasets to format appropriate for framework.
13. Save inferences on all testing datasets.

For checking overfitting, steps up until balancing data can be done once, and then repeat multiple times:
1. Training/validation split.
2. Convert training and validation data to format appropriate for framework.
3. Create model object according to inference target and number of features.
4. Fit model, report fitting process.

Possible implementation.
- Balance :: Create balanced training data. Happens once per training dataset and per inference target. Different data prep functions in a dictionary in utils, and access that using the snakemake wildcard for the inference target.
- Split :: Training/validation split, report distribution. Happens once per model that needs to be fit, using the Fit or SimpleFit rules.
- Fit :: Convert training and validation data to framework format, create model object, fit, report fitting, save model parameters, save inferences on training and validation. Happens once per training dataset, per inference target. Can use multiple cores.
- SimpleFit :: Convert training and validation data to framework format, create model object, fit, report fitting. Happens once per training dataset, per inference target, per overfitting replicate.
- Test :: Load testing data and fit model, save inferences on testing data. Happens once per trained model and per testing data.

Fit and SimpleFit rules use the same notebook, which reads in Snakemake params to decide what to do. That notebook can ad-hoc reduce the size of the training data to speed up training to test if things are working properly.

Configfile has two lists: one for training datasets, one for testing datasets. Also has a list of inference targets. Use those lists to expand inputs and outputs of rules.

Everything should work perfectly well with log-transformed data as well as linearly-transformed data.

**** Task list, not updated.
:PROPERTIES:
:ARCHIVE_TIME: 2022-01-12 Wed 12:32
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:

Preparing Drosophila data:
- Filter raw DGRP data to biallelic sites with not more than 15% missing data.
- Perform imputation on filtered DGRP data.
- Extract Ace, Cyp, and Chkov genotypes for each individual.
- Get pi per site for the filtered/imputed DGRP data.
- Choose which empirical windows to predict on.
- Extract empirical windows from the filtered/imputed DGRP.
- Calculate features for the empirical DGRP windows.
  
Simulation:
- Choose simulation parameters.
- Simulate main model on the cluster.
- Choose robustness parameters.
- Simulate robustness testing datasets on the cluster.
- Check simulation statistics.
- Simulate neutrality to get the simulated SFS.
- Simulate hard sweeps to get average signatures.
  
Training and applying models:
- Create training replicates to check for overfitting and pick ideal # of epochs to train for.
- Train the final model with the chosen # of epochs.
- Perform feature analysis on the main training dataset.
- Train Gradient-Boosted Trees on the main training dataset.
- Apply the trained main model to the robustness testing datasets.
- Calculate performance metrics on all results and post-process those tables.
- Compare the Sweep Mode model performance to the two specialized secondary models.
- Create training replicates to check for overfitting for model trained on partial sweeps.
- Train model on partial sweeps; apply it to empirical data.
- Do a couple of training replicates on empirical data to check that predictions are consistent.
- Calculate performance metrics for model trained on partial sweeps.
  
Model-agnostic plots:
- Plot: methods diagram / graphical abstract.
- Plot: simulated SFS vs. empirical SFS.
- Plot: window size diagram.
- Plot: simulated and empirical sweep signatures.
- Plot: H12 selection scan on DGRP data.
  
Plots for model trained on fixed sweeps:
- Process data for plotting.
- Internal plot: overfitting learning curves.
- Plot: learning curves of final trained models.
- Plot: validation of main models.
- Plot: validation of secondary models.
- Plot: performance of main model divided by selection strength brackets.
- Internal plot: feature distributions in the window around the sweep.
- Plot: predictions of neutral simulated windows.
- Plot: robustness plot with recombination rate and population size.
- Plot: robustness plot with partial sweeps.
- Plot: robustness plot with bottleneck.
- Tables of performance metrics.

Plots for model trained on partial sweeps:
- Internal plot: overfitting learning curves.
- Plot: learning curves of final trained models.
- Plot: basic performance metrics.
- Plot: genome-wide predictions on the DGRP.
- Plot: predictions when you miss the known sweep windows.

*** 2022-01-14 Friday
**** DONE Apply model to robustness datasets. [32/32]
CLOSED: [2022-01-14 Fri 17:30]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/New code written for Drosophila experiments
:END:

- State "DONE"       from "DOING"      [2022-01-14 Fri 17:30]
- State "DOING"      from "TODO"       [2022-01-14 Fri 15:17]

- [X] Prepare a todo list based on the Snakefile.
- [X] Check that we have some pre-trained models ready to go for testing.
- [X] How do we load pre-trained model parameters? What data do we need?
- [X] Put SweepsDataset in the fitting notebook and change code to use that version.
- [X] Load fitting notebook and try =Learner.export.=
- [X] In that same notebook try =Learner.load_learner=.
- [X] Immediately after, try =Learner.load= to load trained parameters.
- [X] If all this works, can we just call =Learner.get_preds=?
- [X] Add a new output to the fitting rule where we save the =.pkl= of the models too.
- [X] Move all of this out of the fitting notebook and into the application notebook.
- [X] Remove SweepsDataset from the fitting notebook and change code to use the original version.
- [X] Load pre-trained model parameters.
- [X] How do we perform predictions on new data? What data do we need?
- [X] Load robustness data as a =SweepsDataset=.
- [X] Get predictions from it
- [X] Apply model to data the same way we did for training and validation.
- [X] Set up a common batch size for fitting and applying the model through =project_parameters=.
- [X] Use the same columns we got from making predictions on training and validation data.
- [X] Test with regression task
- [X] Test with classification task
- [X] Save labels from fitting a model.
  - [X] Save them in regression.
  - [X] Save them in classification.
  - [X] Add labels as input to application rule.
- [X] Add label name to regression task, same format as for training predictions
- [X] Add label names to classification task, same format as for training predictions
- [X] Update git locally and on the cluster.
- [X] Make a rule graph for the inference part of the project.
- [X] Test run it on current data.
- [X] Debug having the =regime_kind= column on robustness data. Right now it only ever appears on training data.
- [X] Test run it again.
- [X] Again update git locally and on the cluster.

*** 2022-01-17 Monday
**** DONE Apply model to empirical data [9/9]
CLOSED: [2022-01-17 Mon 14:55]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/New code written for Drosophila experiments
:END:

- State "DONE"       from "DOING"      [2022-01-17 Mon 14:55]
- State "DOING"      from "TODO"       [2022-01-17 Mon 14:50]
- [X] Open notebook with a regression case and empirical data, try to run it, and see where it fails.
- [X] Add a parameter to indicate whether we're applying to robustness data or empirical data.
- [X] Need a toy parameters DataFrame for empirical data.
- [X] It needs the UUIDs for empirical data.
- [X] It needs toy columns for the target column.
- [X] Test run it with regression.
- [X] Test run it with classification.
- [X] Test run all of it, including the previous robustness data, to make sure everything still works.
- [X] Git update.

**** DONE Get performance metrics from inferences.
CLOSED: [2022-01-17 Mon 14:56]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/New code written for Drosophila experiments
:END:

- State "DONE"       from              [2022-01-17 Mon 14:56]
I have decided to get performance metrics directly from the robustness, training, and validation inferences, /on demand/, as I'm doing the graphs. This facilitates everything.

**** DONE Feature subset analysis [8/8]
CLOSED: [2022-01-17 Mon 15:33]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/New code written for Drosophila experiments
:END:

- State "DONE"       from "DOING"      [2022-01-17 Mon 15:33]
- State "DOING"      from "TODO"       [2022-01-17 Mon 15:06]
- [X] Add rule to perform feature analysis.
- [X] Add function to generate feature subset as a string, 7 characters long, of "0" and "1".
- [X] Add feature subset input to the main rule.
- [X] Test that rule works with =-n= and only one required feature subset.
- [X] Turn feature subset into a list of booleans, not integers.
- [X] Run mock rule with one feature subset.
- [X] Make function generate all 14 feature subsets.
- [X] Git update.

*** 2022-01-24 Monday
**** DONE [#2] Clean up the plotting todo list
CLOSED: [2022-01-24 Mon 11:27]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Run Drosophila analyses and start plots
:END:
- State "DONE"       from "TODO"       [2022-01-24 Mon 11:27]
**** DONE [#2] Prepare Drosophila snakefile for plotting in R [10/10]
CLOSED: [2022-01-24 Mon 11:47]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Run Drosophila analyses and start plots
:END:
- State "DONE"       from "DOING"      [2022-01-24 Mon 11:47]
- State "DOING"      from "TODO"       [2022-01-24 Mon 11:31]
- [X] How to set up an R notebook? Look it up in a search engine.
- [X] Create a tidyverse R conda environment file.
- [X] Create a new Snakefile.
- [X] Create a new bash script to run it.
- [X] Add a toy target, and a toy rule.
- [X] Install conda environment.
- [X] Make rule for plotting the overfitting results, but with toy input.
- [X] Run it with a notebook specification.
- [X] Confirm that the kernel is the right kernel from the environment. I don't think it is.
- [X] Git update.
**** DONE [#1] List all the remaining plots
CLOSED: [2022-01-24 Mon 11:12]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Run Drosophila analyses and start plots
:END:
- State "DONE"       from "DOING"      [2022-01-24 Mon 11:12]
- State "DOING"      from "TODO"       [2022-01-24 Mon 11:07]

*** 2022-01-25 Tuesday
**** DONE Run model fitting for Drosophila [8/8]
CLOSED: [2022-01-25 Tue 11:37]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Run Drosophila analyses and start plots
:END:

- State "DONE"       from "DOING"      [2022-01-25 Tue 11:37]
- State "DOING"      from "TODO"       [2022-01-24 Mon 19:52]
- [X] Take number of training epochs out of =project_parameters= and put in =03_config.yaml=.
- [X] Make it so overfitting replicates can run 60 epochs.
- [X] Make it so regular analyses can run 25 epochs.
- [X] Make it so debugging analyses can run 1 epoch.
- [X] Clear directory of results.
- [X] Test everything with only one epoch.
- [X] Start running overfitting replicates.
- [X] Wait for things to finish.

**** DONE Plot: Drosophila overfitting results [11/11]
CLOSED: [2022-01-25 Tue 15:15]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Run Drosophila analyses and start plots
:END:
- State "DONE"       from "DOING"      [2022-01-25 Tue 15:15]
- State "DOING"      from "TODO"       [2022-01-25 Tue 11:39]
- [X] Check out input files.
- [X] Make rule with 4 separate inputs, one per target. Rule is wildcarded by partial/fixed.
- [X] Make targets into a factor, encode this in a function.
- [X] Pick a plot size, encode that in a function.
  - How wide is a letter page? Plot should be circa 2/3 of page. What does PLoS say?
- [X] Pick a text size, encode that in a function.
- [X] Pick a colour palette, encode that in a variable.
- [X] Adjust plot according to the other plotting principles.
- [X] Add the formal overfitting methods from the previous code? Or not?
- [X] Run both fixed and partial sweep plots.
- [X] Git update.
- [X] Try it again with hrbrthemes.

*** 2022-01-31 Monday
**** DONE Plot: Diagram of inference method
CLOSED: [2022-01-31 Mon 18:22]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "TODO"       [2022-01-31 Mon 18:22]
**** DONE Plot: Subwindows
CLOSED: [2022-01-31 Mon 18:22]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "TODO"       [2022-01-31 Mon 18:22]

** 2022-02 February

*** 2022-02-01 Tuesday
**** DONE Plot: Validation of fixed sweep models [24/24]
CLOSED: [2022-02-01 Tue 11:48]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "DOING"      [2022-02-01 Tue 11:48]
- [X] Copy previous notebook
- [X] Selection strength regressions
- [X] Confusion matrix for sweep mode
- [X] Prepare ROC curves
- [X] ROC curves for sweep mode
- [X] Prepare feature analysis data in Python
  - [X] What are all the inputs that I need?
  - [X] Calculate RMSE or accuracy for one feature subset
  - [X] Calculate RMSE or accuracy for all feature subsets
  - [X] Make table of feature code vs. 0/1 feature presence
  - [X] Change input of preparation to include baseline performance
  - [X] Add row of basic performance
- [X] Order x-axis and y-axis in feature analysis grid properly
- [X] Confirm that baseline row works in the plot
- [X] Color scale of feature analysis, including separate colour for the baseline performance
- [X] Put all plots together
  - [X] Align
  - [X] Check that label positions are good
  - [X] Space plots out in grids
  - [X] Pick the final plot size
- [X] Rewrite rules that calculate metrics to be more informative.
- [X] Rewrite ROC rule to produce AUC.
- [X] Test everything together.
- [X] Git update
**** DONE Plot: Validation of secondary fixed sweep models
CLOSED: [2022-02-01 Tue 16:51]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "DOING"      [2022-02-01 Tue 16:51]
- State "DOING"      from "SOON"       [2022-02-01 Tue 16:28]
- State "SOON"       from "TODO"       [2022-01-31 Mon 18:22]
- [X] Copy a new notebook, based on partial sweep validation.
- [X] Make rule, with inputs and output.
- [X] Prepare ROC curves for binary classifications.
- [X] Modify notebook to make the right plot.
- [X] Run feature analysis prep for the two binary classifications.
- [X] Copy code of feature analysis from fixed sweeps validation.
- [X] Make the plot.
- [X] Git update.
**** DONE Plot: Validation of partial sweeps model
CLOSED: [2022-02-01 Tue 18:42]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "DOING"      [2022-02-01 Tue 18:42]
- State "DOING"      from "DONE"       [2022-02-01 Tue 18:36]
- State "DONE"       from "DOING"      [2022-02-01 Tue 16:22]
- State "DOING"      from "TODO"       [2022-02-01 Tue 16:14]
- State "SOON"       from "TODO"       [2022-01-31 Mon 18:22]
- [X] Rename main-validation to fixedsweeps-validation.
- [X] Copy notebook for partial validation.
- [X] Create separate rule with separate notebook for partial validation.
- [X] Check previous partial validation plot to see what needs to go in it.
- [X] Run ROC curve of partial sweeps.
- [X] Go through the notebook, making changes as necessary.
- [X] Change =parameters= input of fixed sweeps validation rule.
- [X] Run both fixedsweeps and partialsweeps figures.
- [X] Git update.
- [X] Save metrics.
- [X] Clean temp notebook folder.
- [X] Git update.
**** DONE Plot: Robustness to bottlenecks
CLOSED: [2022-02-01 Tue 18:36]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "DOING"      [2022-02-01 Tue 18:36]
- State "DOING"      from "TODO"       [2022-02-01 Tue 18:24]
- State "DONE"       from "TODO"       [2022-02-01 Tue 18:12]
- State "SOON"       from "TODO"       [2022-01-31 Mon 18:22]
- [X] Check previous plot.
- [X] Save RMSE, MRE, accuracy, somewhere!
**** DONE Plot: Timing and errors of sweeps happening during bottleneck
CLOSED: [2022-02-01 Tue 18:12]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "TODO"       [2022-02-01 Tue 18:12]
- State "SOON"       from "TODO"       [2022-01-31 Mon 18:22]
- Color scheme of sweep timing plot, make the plot way clearer. Can we even add selection coefficient to the plot? Without making it a 3D plot? I think we might be able to add a second panel. Same plot of sweep timings, but color in one is "error" and color in the other is the coefficient itself.

*** 2022-02-02 Wednesday
**** DONE Plot: Validation of main model split by selection coefficient
CLOSED: [2022-02-02 Wed 15:15]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "DOING"      [2022-02-02 Wed 15:15]
- State "DOING"      from "DONE"       [2022-02-02 Wed 15:07]
- State "DONE"       from "DOING"      [2022-02-01 Tue 18:22]
- State "DOING"      from "DONE"       [2022-02-01 Tue 17:50]
- State "DONE"       from "TODO"       [2022-02-01 Tue 16:09]
- State "SOON"       from "TODO"       [2022-01-31 Mon 18:22]
- [X] Check previous plot, brainstorm how to reproduce it from scratch
- I'm going to do horizontal bar plots.
- It's going to be 2 independent plots from regular validation, joined by cowplot.
- I'll need some sort of cut function to group selection coefficient by.
- [X] Make rule, inputs, notebook.
- [X] Add a row of "all" with overall performance.
- [X] Make plot for selection strength.
- [X] Adjust plot style for selection strength.
  - [X] Different color for "all" column.
  - [X] Better bracket labels.
- [X] Do the same for sweep mode.
- [X] Plot them together.
- [X] Git update.
- [X] What is the "relative error" we had in the plot before?
- [X] Fix ordering of selection brackets
**** DONE Plot: Robustness to recombination and population size
CLOSED: [2022-02-02 Wed 12:17]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "DOING"      [2022-02-02 Wed 12:17]
- State "DOING"      from "SOON"       [2022-02-02 Wed 11:11]
- State "SOON"       from "TODO"       [2022-01-31 Mon 18:22]
- [X] Check previous plot.
- [X] Make rule with the right inputs and output.
- [X] Load and filter data in the notebook.
- [X] Save RMSE, MRE, and Accuracy.
- [X] Make the plot.
  - [X] A column of selection strength
  - [X] s and s/r plots in the same graphs
  - [X] A column of confusion matrices
  - [X] Proper labels and spacing
- [X] Git update.
**** DONE Plot: Robustness to offcenter sweeps
CLOSED: [2022-02-02 Wed 15:19]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "DOING"      [2022-02-02 Wed 15:19]
- State "DOING"      from "TODO"       [2022-02-02 Wed 14:42]
- [X] Check previous plot.
- [X] Make rule with the right inputs and output.
- [X] Filter data properly within the notebook.
- [X] Make the plot.
- [X] Fix ordering of selection brackets
- [X] Save metrics.
- [X] Git update.
**** DONE Plot: Robustness to partial sweeps
CLOSED: [2022-02-02 Wed 16:34]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "SOON"       [2022-02-02 Wed 16:34]
- State "SOON"       from "DOING"      [2022-02-02 Wed 14:40]
- State "DOING"      from "TODO"       [2022-02-02 Wed 14:38]
- State "DOING"      from "SOON"       [2022-02-02 Wed 12:20]
- State "SOON"       from "TODO"       [2022-01-31 Mon 18:22]
- [X] Check previous plot.
- [X] Make rule with the right inputs and output.
- [X] Filter data properly within the notebook.
- [X] Save RMSE, MRE, and Accuracy, somehow.
- [X] Make the plot.
- [X] Git update.
**** DONE Sweep timing sanity check
CLOSED: [2022-02-02 Wed 15:44]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:

- State "DONE"       from "DOING"      [2022-02-02 Wed 15:44]
- State "DOING"      from "TODO"       [2022-02-02 Wed 14:11]
- [X] Locally make configs for hard sweep with s=0.5, s=1, s=5, s=10
- [X] Simulate them locally, I just want their SLiM scripts.
- [X] Adapt SLiM scripts such that I can simulate just the one selected site from them.
- [X] Create one SLiM script per selection coefficient.
- [X] Output sweep time at the end of the script.
- [X] Simulate each selection coefficient a bunch of times.
- [X] Concatenate sweep times into a table
- [X] Plot the distribution of sweep times
- [X] Calculate the mean/median of sweep times
- [X] Git update

**** DONE Sweep timing sanity check
CLOSED: [2022-02-02 Wed 15:44]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:52
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:

- State "DONE"       from "DOING"      [2022-02-02 Wed 15:44]
- State "DOING"      from "TODO"       [2022-02-02 Wed 14:11]
- [X] Locally make configs for hard sweep with s=0.5, s=1, s=5, s=10
- [X] Simulate them locally, I just want their SLiM scripts.
- [X] Adapt SLiM scripts such that I can simulate just the one selected site from them.
- [X] Create one SLiM script per selection coefficient.
- [X] Output sweep time at the end of the script.
- [X] Simulate each selection coefficient a bunch of times.
- [X] Concatenate sweep times into a table
- [X] Plot the distribution of sweep times
- [X] Calculate the mean/median of sweep times
- [X] Git update

**** DONE Make testing inferences on partial sweeps using fixed sweeps model
CLOSED: [2022-02-02 Wed 15:55]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:52
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:
- State "DONE"       from "DOING"      [2022-02-02 Wed 15:55]
- State "DOING"      from "SOON"       [2022-02-02 Wed 15:54]
- [X] Make a rule in inference, with the right inputs.
- [X] Run the rule.
- [X] Make sure outputs are okay.

**** DONE Run simulations on the cluster to get simulated Drosophila SFS
CLOSED: [2022-02-02 Wed 16:45]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:52
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:
- State "DONE"       from "TODO"       [2022-02-02 Wed 16:45]
- [X] Get the saving of genotypes from the Turkana data
- [X] Create a slurm script to submit, say, 100 neutral simulations.
- [X] Git update.
- [X] Send simulations to the cluster.
  

*** 2022-02-03 Thursday
**** DONE Plot: Learning curves of fixed sweep models
CLOSED: [2022-02-03 Thu 14:00]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "DOING"      [2022-02-03 Thu 14:00]
- State "DOING"      from "TODO"       [2022-02-03 Thu 13:36]
- State "SOON"       from "TODO"       [2022-01-31 Mon 18:22]
- [X] Check previous plot.
- [X] Make rule with inputs and outputs.
- [X] Copy notebook of overfitting learning curves.
- [X] Edit plot.
- [X] Add y-axis to overfitting learning curves and regular learning curves.
- [X] Add labels (A, B, C, D) and refer to it in the text as Figure A, B. Because we talk about those panels way before we talk about C and D.
- [X] Git update.
**** DONE Plot: Learning curves of partial sweep models
CLOSED: [2022-02-03 Thu 13:45]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "TODO"       [2022-02-03 Thu 13:45]
- State "SOON"       from "TODO"       [2022-01-31 Mon 18:22]
- Add labels (A, B, C, D) and refer to it in the text as Figure A, B. Because we talk about those panels way before we talk about C and D.
- [X] Check previous plot.
- [X] Try to adapt the previous rule using the right wildcards.
- [X] Check that it worked.

*** 2022-02-04 Friday
**** DONE Plot: Sweep signatures
CLOSED: [2022-02-04 Fri 18:50]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "DOING"      [2022-02-04 Fri 18:50]
- State "DOING"      from "SOON"       [2022-02-03 Thu 21:08]
- State "SOON"       from "DOING"      [2022-02-03 Thu 19:24]
- State "DOING"      from "SOON"       [2022-02-03 Thu 18:50]
- State "SOON"       from "TODO"       [2022-01-31 Mon 18:22]
- [X] Check previous plots
- [X] Open previous notebook
- [X] Git update.
- [X] Run hard sweeps with known s on the cluster.
- [X] Wait for hard sweeps to finish running.
- [X] Download hard sweeps to a new simulation folder.
- [X] Make rule to produce table of sweep signatures from empirical and simulated data
- [X] Make rule for plotting the signatures and producing two plots
- [X] One plot for control loci
- [X] One plot for examples of simulated loci
- [X] Adjust appearance of plots
- [X] Git update
**** DONE Plot: Simulated vs. empirical SFS
CLOSED: [2022-02-04 Fri 17:15]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "DOING"      [2022-02-04 Fri 17:15]
- State "DOING"      from "SOON"       [2022-02-03 Thu 21:08]
- State "SOON"       from "TODO"       [2022-01-31 Mon 18:22]
- [X] Debug why neutral simulations never finished.
- [X] Wait for neutral simulations to finish on the cluster.
- [X] Download simulations to a folder that isn't used for training or anything else.
- [X] Create a rule for deriving the empirical SFS.
- [X] Copy the notebook from Turkana about preparing the empirical and simulated SFS.
- [X] Copy the notebook from Turkana about plotting the empirical and simulated SFS.
- [X] Let's some equidistant bins. And do the unnormalized SFS. Divide raw # of SNPs in the DGRP by the total number of megabases and plot the /unnormalized/ SFS /per megabase/. For simulations, sum over every simulation of 1Mb each and divide by the total number of simulations.
- [X] Git update.
**** DONE Fix up Drosophila plots based on meeting results
CLOSED: [2022-02-04 Fri 17:53]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:51
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila plots
:END:
- State "DONE"       from "TODO"       [2022-02-04 Fri 17:53]
- [X] Could we color the bottleneck sweeps by the ones that /started/ during the bottleneck adn the ones that /started/ before the bottleneck? Both categories of sweeps that fixed during the bottleneck.
- [X] Control order of bottleneck plotting such that it doesn't look like the red dots are being hidden by the grey ones.
- [X] Plot MRE in all plots, not inverse, not 1 minus. Maybe add label with which direction is better?

*** 2022-02-10 Thursday
**** DONE Drosophila manuscript loose ends [20/20]
CLOSED: [2022-02-10 Thu 19:23]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:52
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila manuscript
:END:

- State "DONE"       from "DOING"      [2022-02-10 Thu 19:23]
- State "DOING"      from "SOON"       [2022-02-10 Thu 16:38]
- State "SOON"       from              [2022-02-07 Mon 10:57]

- [X] Check Overleaf.
- [X] Pull Overleaf.
- [X] Selection coefficient vs. strength.
- [X] Partial sweeps always, never "incomplete" sweeps.
- [X] Cite: Pritchard et al.: Hard sweep, soft sweep, and polygenic adaptation. Statement: In nature, most sweeps might be partial.
- [X] Cite things that predict s, softness
- [X] Cite things that are supervised machine learning
- [X] Take it out of KOMA.
- [X] Update all plots.
- [X] Update number formatting.
- [X] Make a =kb= command.
- [X] Software availability sentence, with link to put in.
- [X] Figure and table captions.
- [X] Update all numbers. Search for =\num= and =$= and =\perc= and kb and Mb.
- [X] Inferred vs predicted
- [X] MRE definition
- [X] Search for "cite"
- [X] Larger margins.
- [X] Section numbers.
- [X] Go through every single warning.

*** 2022-02-11 Friday
**** DONE Drosophila manuscript modifications [12/12]
CLOSED: [2022-02-11 Fri 16:12]
:PROPERTIES:
:ARCHIVE_TIME: 2022-02-14 Mon 09:52
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps/Drosophila manuscript
:END:

- State "DONE"       from "TODO"       [2022-02-11 Fri 16:12]
- [X] Add offcenter sweeps as paragraph of Robustness evaluation. Toward the end: are we robust to misspecification of precise adaptive location? Use the offcenter analyses. We expect to lose power for weaker s, because the signals are smaller and your windows go off the sweep zone. If we're more off than the sweep size, it wouldn't make sense. Possibly only supplement, Philipp doesn't think we need a plot. Our method assumes we know the precise location of the sweep; in reality, this might not be so clear because one might not know the actual location. How robust is our method in that scenario? To test this, we applied trained model to validation set with offcenter sweeps.
- [X] x-axis labels in the middle, not to the right.
- [X] Maybe add spacing between panels instead of slanting s in Fig. 5 and similar
- [X] "s" instead of "sel. strength"
- [X] Smaller scatter plots.
- [X] Reverse colours on confusion matrices.
- [X] ggplot: title in figures still bigger than all the other fonts
- [X] Over how many hard sweeps are we averaging for Supp. Fig. 2?
- [X] Fig. S4 caption.
- [X] Turn Fig. 9 into a Supporting Figure, change Cyp to Cyp6g1 etc.
- [X] Bring back supplement part about overall Drosophila windows.
- [X] Desai citation: https://doi.org/10.1534/genetics.106.067678

*** 2022-02-18 Friday
**** DONE Results in Drosophila manuscript [3/3]
CLOSED: [2022-02-18 Fri 15:45] DEADLINE: <2022-02-18 Fri>
:PROPERTIES:
:ARCHIVE_TIME: 2022-03-03 Thu 18:19
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_ITAGS: project
:ARCHIVE_OLPATH: PhD/Drosophila sweeps
:END:
- State "DONE"       from              [2022-02-18 Fri 15:45]
***** DONE Re-train Drosophila models with 50 epochs. [4/4]
CLOSED: [2022-02-15 Tue 09:11]
- State "DONE"       from "DOING"      [2022-02-15 Tue 09:11]
- State "DOING"      from "TODO"       [2022-02-14 Mon 15:46]
- State "SOON"       from              [2022-02-14 Mon 10:37]
- [X] Backup output files somewhere.
- [X] Dry run to see that everything will be OK.
- [X] No need to run overfitting replicates.
- [X] Run overnight.
  
***** DONE Re-run plots and numbers.
CLOSED: [2022-02-15 Tue 12:25]
- State "DONE"       from "TODO"       [2022-02-15 Tue 12:25]
- State "SOON"       from              [2022-02-14 Mon 10:37]
- Overfitting plots don't need to be redone.
  
***** DONE Non-CNN model training in Drosophila [20/20]
CLOSED: [2022-02-18 Fri 15:45]

- State "DONE"       from "DOING"      [2022-02-18 Fri 15:45]
- State "DOING"      from "SOON"       [2022-02-18 Fri 11:51]
- State "SOON"       from              [2022-02-14 Mon 10:37]
- [X] Copy rule and notebook for fitting deep learning.
- [X] Add gradient boosting parameters to =project_parameters.py=
- [X] Create training/validation SweepsDatasets.
- [X] Flatten and load X and y arrays for training and validation.
- [X] Train for the right targets.
- [X] Produce an output dataframe of predictions.
  - [X] Get predictions for classification.
  - [X] Change classification column names.
  - [X] Add true column to predictions.
  - [X] Repeat for training and validation.
  - [X] Get predictions for regression.
  - [X] Change regression column names.
  - [X] Add true column to predictions.
- [X] Run all with 1 estimator, test that it works.
- [X] Git update.
- [X] New rule for plotting gradient boosting validation; base it on main model.
- [X] Do the plot.
- [X] Save those metrics: MRE and RMSE of sel. strength for all, hard, RNM, SGV. Accuracy of sweep mode.
- [X] Git update.
- [X] Run all with 500 estimators.

*** 2022-02-21 Monday
**** DONE Better metrics
CLOSED: [2022-02-21 Mon 13:16]
:PROPERTIES:
:ARCHIVE_TIME: 2022-03-09 Wed 12:26
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_OLPATH: PhD/Drosophila project/Last Drosophila results
:END:

- State "DONE"       from "DOING"      [2022-02-21 Mon 13:16]
- State "DOING"      from "SOON"       [2022-02-21 Mon 12:40]
- State "SOON"       from              [2022-02-21 Mon 11:50]
- [X] Rename metrics output, make them consistent and understandable.
- [X] Use metrics from gradient boost as basis to get main model metrics.
- [X] Make sure everything connects with =-n=.
- [X] Run everything.
- [X] Git update.

** 2022-03 March

*** 2022-03-01 Tuesday
**** DONE Make replicate empirical Drosophila inferences
CLOSED: [2022-03-01 Tue 15:38]
:PROPERTIES:
:ARCHIVE_TIME: 2022-03-09 Wed 12:26
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_OLPATH: PhD/Drosophila project/Last Drosophila results
:END:
- State "DONE"       from "DOING"      [2022-03-01 Tue 15:38]
- State "DOING"      from "DONE"       [2022-02-25 Fri 13:59]
- State "DONE"       from "DOING"      [2022-02-25 Fri 11:54]
- [X] Add replicates of training runs to =all= rule.
- [X] Create a new rule. I don't think I need to change any notebooks or anything.
- [X] Test it with =-n=.
- [X] Git update.
- [X] Run it.
- [X] Look at replicates of predictions to tell Philipp.
- [X] Make a rule with a script.
- [X] Git update.

*** 2022-03-02 Wednesday
**** DONE Drosophila learning curve by sample size [22/22]
CLOSED: [2022-03-02 Wed 13:59]
:PROPERTIES:
:ARCHIVE_TIME: 2022-03-09 Wed 12:26
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_OLPATH: PhD/Drosophila project/Last Drosophila results
:END:

- State "DONE"       from "DOING"      [2022-03-02 Wed 13:59]
- State "DOING"      from "TODO"       [2022-03-02 Wed 13:04]
Do a learning curve to see if we have enough training examples.

- [X] Make a rule for each target.
- [X] Test that everything works with =-n=.
- [X] In a notebook per target:
  - [X] Subset training and validation to a smaller size, rebalancing it.
  - [X] Fit models at increasing sample sizes.
  - [X] scikit learn user guide: do we use the same validation set, always?
- [X] Collate all results into a table per target, including the employed sample size.
- [X] Balance training datasets.
- [X] Test the balancing with a hard vs. soft example.
- [X] Run everything with tiny sample sizes, tiny epochs.
- [X] Plotting rule: put results for each target together, make plot. Wildcard by training data, just like the other learning curves.
- [X] Copy learning curve notebook.
- [X] Then plot everything. Also, report the sample size somewhere.
- [X] Run plotting rules to make sure they work.
- [X] Add overfitting replicates to learning curve rule.
- [X] Run again, make sure it works.
- [X] Update input for learning curve plotting rule.
- [X] Update plotting notebook for learning curve replicates.
- [X] Remove all placeholder code and comments from fitting notebook.
- [X] Config goes back to 10 overfitting replicates.
- [X] Clear folder of temporary notebooks.
- [X] Git update.
  
**** DONE Genome-wide Drosophila predictions [19/19]
CLOSED: [2022-03-02 Wed 16:27]
:PROPERTIES:
:ARCHIVE_TIME: 2022-03-09 Wed 12:26
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_OLPATH: PhD/Drosophila project/Last Drosophila results
:END:

- State "DONE"       from "DOING"      [2022-03-02 Wed 16:27]
- State "DOING"      from "TODO"       [2022-03-02 Wed 13:46]
- State "SOON"       from              [2022-02-21 Mon 11:50]
- [X] Review how we make empirical windows now
- [X] Empirical window commands notebook
- [X] Inspiration from previous notebook on empirical windows
- [X] Run with smaller data: Make empirical windows
- [X] Rule: apply model to empirical
- [X] Rule: make neutral simulation parameter TSVs
- [X] Rule: apply model to neutral simulations. Base on applying model to partial sweeps.
- [X] Model application notebook
- [X] Change num of epochs to 3
- [X] Run neutral inferences
- [X] Plot rule for genomewide predictions (only fixedsweeps selstren and sweep mode)
- [X] Plot notebook based on previous plot
  - [X] Plan the 2 cowplot components, what data do I need?
  - [X] Load data separating between empirical and neutral cases
  - [X] Make component 1
  - [X] Make component 2
- [X] Change num of epochs back in config
- [X] Learning curves removing up to epoch 25
- [X] Git update

*** 2022-03-04 Friday
**** DONE Manual cleaning of citations in Drosophila manuscript
CLOSED: [2022-03-04 Fri 10:58]
:PROPERTIES:
:ARCHIVE_TIME: 2022-03-09 Wed 12:27
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_OLPATH: PhD/Drosophila project/Final Drosophila manuscript
:END:

- State "DONE"       from "DOING"      [2022-03-04 Fri 10:58]
- State "DOING"      from "TODO"       [2022-03-04 Fri 10:27]
- [X] Pull Overleaf locally
- [X] What's wrong with the citations from my own point of view?
- [X] Use the PLoS guidelines to create a citation todo list here.
- [X] Species names formatted properly.
- [X] All-caps in a row.
- [X] Review all citations by eye.
- [X] Update git and Overleaf.


*** 2022-03-07 Monday
**** DONE Run Drosophila [19/19]
CLOSED: [2022-03-07 Mon 17:12]
:PROPERTIES:
:ARCHIVE_TIME: 2022-03-09 Wed 12:26
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_OLPATH: PhD/Drosophila project/Last Drosophila results
:END:

- State "DONE"       from "TODO"       [2022-03-07 Mon 17:12]
- State "DOING"      from "TODO"       [2022-03-04 Fri 10:26]
- State "DOING"      from "SOON"       [2022-03-02 Wed 16:44]
- [X] Remove overfitting curves from inference and plotting.
- [X] Something might go wrong now that we have more than just sweeps as our empirical results. Where do we use them?
  - [X] Make table of empirical results
  - [X] Prepare sweep signals
- [X] Run preparation of data
- [X] Run model training and inference
- [X] Run plotting
- [X] Confirm that everything looks good
- [X] Plot for null predictions isn't working - why?
- [X] All the predictions for the genome-wide data are the same. Fix it.
  - [X] Are the genomewide data identical? Yes. How?
  - [X] Change naming of empirical windows to =genomewide_chrom=
- [X] Delete empirical windows.
- [X] Re-run data preparation to remake empirical windows.
- [X] Delete empirical inferences.
- [X] Re-run empirical inferences.
- [X] Re-run all plotting.
- [X] Remove backup folders for output and figures
- [X] Git update

*** 2022-03-08 Tuesday
**** DONE Put new plots/results/numbers in manuscript [21/21]
CLOSED: [2022-03-08 Tue 16:09]
:PROPERTIES:
:ARCHIVE_TIME: 2022-03-09 Wed 12:27
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_OLPATH: PhD/Drosophila project/Final Drosophila manuscript
:END:
- State "DONE"       from "DOING"      [2022-03-08 Tue 16:09]
- State "DOING"      from "TODO"       [2022-03-08 Tue 11:58]
- [X] Pull Overleaf locally
- [X] Fix empirical inference replicates
  - [X] Save "statistics" files with an index.
  - [X] Move rule to the inference workflow.
  - [X] Move notebook to the inference folder.
  - [X] Re-run.
  - [X] Git update.
- [X] Add empirical inference replicates
  - [X] Remove Table 3.
  - [X] Add sentence about making model training replicates.
  - [X] Put sel. strength inferences in each locus's paragraph.
  - [X] Add empirical inference error/replicates/uncertainty to the results, as a placeholder. Just put it in the text. Do this for each empirical inference.
  - [X] Add IQR to empirical replicate summaries.
  - [X] Clear temporary notebooks folder.
  - [X] Git update.
  - [X] Add the real empirical inference replicate numbers to the manuscript.
- [X] Replace =WHY= tag of sweep duration with a placeholder explanation that Philipp can expand.
- [X] Change all plots to current ones.
- [X] Add subheadings to Supplementary paragraphs.
- [X] Relegate offcenter robustness plot to the Supplementary.
- [X] Add offcenter sweeps as paragraph of Robustness evaluation.
  
**** DONE Review Drosophila manuscript [100%]
CLOSED: [2022-03-08 Tue 17:11]
:PROPERTIES:
:ARCHIVE_TIME: 2022-03-09 Wed 12:27
:ARCHIVE_FILE: ~/pessoal/essencial/agenda.org
:ARCHIVE_CATEGORY: PhD
:ARCHIVE_TODO: DONE
:ARCHIVE_OLPATH: PhD/Drosophila project/Final Drosophila manuscript
:END:
- State "DONE"       from "DOING"      [2022-03-08 Tue 17:11]
- State "DOING"      from "TODO"       [2022-03-08 Tue 16:29]
- [X] Page 3
- [X] Page 4
- [X] Page 5
- [X] Page 6
- [X] Page 7
- [X] Page 8
- [X] Page 9
- [X] Page 10
- [X] Page 11
- [X] Page 12
- [X] Page 13
- [X] Page 14
- [X] Page 15
- [X] Page 16
- [X] Page 17
- [X] Page 18
- [X] Page 19
- [X] Page 20
- [X] Page 21
- [X] Page 22
- [X] Page 23
- [X] Page 24
- [X] Change all numbers to current predictions.
- [X] Move supporting figures and tables so they're in the same order as they appear in the text.
- [X] Git and Overleaf update.
- [X] Email Philipp when numbers are in place.
