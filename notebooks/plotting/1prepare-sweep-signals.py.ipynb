{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweeps = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab all the empirical signatures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(snakemake.input[\"empirical\"]) as tar:\n",
    "    members = tar.getmembers()\n",
    "    for member in members:\n",
    "        if member.isdir():\n",
    "            continue\n",
    "        array_file = BytesIO()\n",
    "        array_file.write(tar.extractfile(member).read())\n",
    "        array_file.seek(0)\n",
    "        np_array = np.load(array_file).transpose([2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ms_file in tqdm.notebook.tqdm(ms_files):\n",
    "    with tarfile.open(ms_file) as f:    \n",
    "        members = f.getmembers()\n",
    "        for member in members:\n",
    "            if member.isdir():\n",
    "                continue\n",
    "            fileobj = TextIOWrapper(f.extractfile(member))\n",
    "            positions, genotypes = ms_to_numpy(fileobj)\n",
    "            sfs.update(genotypes.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuids = self.df.uuid\n",
    "for uuid in tqdm.notebook.tqdm(uuids):\n",
    "    name = uuid + \".npy\"\n",
    "    array_file = BytesIO()\n",
    "    array_file.write(data.extractfile(name).read())\n",
    "    array_file.seek(0)\n",
    "    np_array = np.load(array_file).transpose([2, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from random import choice\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_size_bp = 1e6\n",
    "DIMENSION = 21\n",
    "WINDOW_SIZES = np.exp(np.linspace(np.log(1000), np.log(loc_size_bp/((DIMENSION + 1)/2)), DIMENSION))\n",
    "WINDOW_SIZES = [np.round(i) for i in WINDOW_SIZES]\n",
    "WINDOW_SIZES = [rev for rev in reversed(WINDOW_SIZES)]\n",
    "FEATURES = ['pi', 'snps', 'haps', 'H1', 'H12', 'H2overH1', 'tajD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidify(path):\n",
    "    \"\"\"Turns the .npy file in the path into a tidy table of statistics.\"\"\"\n",
    "    if isinstance(path, list):\n",
    "        mean = np.zeros(shape=(DIMENSION, DIMENSION, len(FEATURES)))\n",
    "        n = 0\n",
    "        for arr_path in tqdm_notebook(path):\n",
    "            array = np.load(arr_path)\n",
    "            mean += array\n",
    "            n += 1\n",
    "        x = mean/n\n",
    "    else:\n",
    "        x = np.load(path)\n",
    "    coords, values = zip(*np.ndenumerate(x))\n",
    "    df = (\n",
    "        pd\n",
    "        .DataFrame(coords, columns=['window_size', 'position', 'feature'])\n",
    "        .assign(value=values)\n",
    "    )\n",
    "    df = df.assign(\n",
    "        window_size=[WINDOW_SIZES[i] for i in df.window_size],\n",
    "        feature=[FEATURES[i] for i in df.feature]\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_sweeps = list(Path('../../../raw-data/20210521_data/hardsweeps/s0.01-2133504-final/data').glob('*.npy'))\n",
    "strong_sweeps = list(Path('../../../raw-data/20210521_data/hardsweeps/s100.0-2133505-final/data').glob('*.npy'))\n",
    "\n",
    "to_tidify = {\n",
    "    'Ace': list(Path('../output/drosophila/empirical-window-npy/').glob('sweep-ace*'))[0],\n",
    "    'Cyp': list(Path('../output/drosophila/empirical-window-npy/').glob('sweep-cyp*'))[0],\n",
    "    'CHKoV': list(Path('../output/drosophila/empirical-window-npy/').glob('sweep-chkov*'))[0],\n",
    "    'Average hard sweep\\n(s=0.01)': weak_sweeps,\n",
    "    'Average hard sweep\\n(s=100)': strong_sweeps,\n",
    "}\n",
    "\n",
    "num_hard_sweep_examples = 2\n",
    "for example in range(1, num_hard_sweep_examples + 1):\n",
    "    to_tidify[f'Hard sweep example {example}\\n(s=0.01)'] = choice(weak_sweeps)\n",
    "    to_tidify[f'Hard sweep example {example}\\n(s=100)'] = choice(strong_sweeps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for case, path in to_tidify.items():\n",
    "    dfs.append(tidify(path).assign(case=case))\n",
    "signals = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals.to_csv('../output/signals/signals.csv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
